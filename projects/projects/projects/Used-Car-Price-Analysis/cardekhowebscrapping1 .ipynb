{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a963c495-3322-4073-b55b-53cee7a91731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting scraper...\n",
      "Scraping Maharashtra...\n",
      "Scraping Uttar Pradesh...\n",
      "Scraping Karnataka...\n",
      "Scraping Gujarat...\n",
      "Scraping Rajasthan...\n",
      "Scraping Madhya Pradesh...\n",
      "Scraping Tamil Nadu...\n",
      "Scraping Haryana...\n",
      "Scraping Kerala...\n",
      "Scraping Delhi...\n",
      "Scraping Bihar...\n",
      "Scraping Jharkhand...\n",
      "Scraping Chhattisgarh...\n",
      "Scraping Odisha...\n",
      "Scraping West Bengal...\n",
      "\n",
      "Scraped 300 rows.\n",
      "Cleaned data: 300 rows.\n",
      "\n",
      "Data saved to used_cars_20250717_095647.csv in 45.10 seconds.\n",
      "\n",
      "Sample:\n",
      "                              Car Name     Location  Price (INR) Fuel Type  \\\n",
      "0  2023 Hyundai ExterSX CNG 4 Cylinder  Maharashtra       890000       Cng   \n",
      "1          2024 Kia SonetHTX Turbo DCT  Maharashtra      1325000    Petrol   \n",
      "2             2024 Audi Q3Bold Edition  Maharashtra      4450000    Petrol   \n",
      "3                2022 Renault KigerRXT  Maharashtra       604000    Petrol   \n",
      "4               2024 Maruti CelerioZXI  Maharashtra       595000    Petrol   \n",
      "\n",
      "  Transmission  Km Driven  Manufacture Year    Brand  \n",
      "0       Manual        NaN              2023  Hyundai  \n",
      "1    Automatic        NaN              2024      Kia  \n",
      "2    Automatic        NaN              2024     Audi  \n",
      "3       Manual        NaN              2022  Renault  \n",
      "4       Manual        NaN              2024   Maruti  \n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import quote_plus\n",
    "import pandas as pd\n",
    "import time\n",
    "import re\n",
    "from random import uniform\n",
    "\n",
    "# Configurations\n",
    "BASE_URL = \"https://www.cardekho.com/used-cars+in+\"\n",
    "HEADERS = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)'\n",
    "}\n",
    "STATES = [\n",
    "    \"Maharashtra\", \"Uttar Pradesh\", \"Karnataka\", \"Gujarat\", \"Rajasthan\",\n",
    "    \"Madhya Pradesh\", \"Tamil Nadu\", \"Haryana\", \"Kerala\", \"Delhi\",\n",
    "    \"Bihar\", \"Jharkhand\", \"Chhattisgarh\", \"Odisha\", \"West Bengal\"\n",
    "]\n",
    "\n",
    "def extract_specs(card, car_name):\n",
    "    \"\"\"Extracts specifications from a car listing card.\"\"\"\n",
    "    specs = {'Fuel Type': 'N/A', 'Transmission': 'N/A', 'Km Driven': 'N/A', 'Manufacture Year': 'N/A'}\n",
    "    \n",
    "    specs_div = card.find('div', class_='dotsDetails')\n",
    "    if specs_div:\n",
    "        texts = [t.strip().lower() for t in specs_div.stripped_strings]\n",
    "        for fuel in ['petrol', 'diesel', 'cng', 'electric', 'hybrid']:\n",
    "            if fuel in texts:\n",
    "                specs['Fuel Type'] = fuel.title()\n",
    "                break\n",
    "        for trans in ['manual', 'automatic']:\n",
    "            if trans in texts:\n",
    "                specs['Transmission'] = trans.title()\n",
    "                break\n",
    "        km = next((t for t in texts if 'km' in t), None)\n",
    "        if km:\n",
    "            km_val = re.sub(r'[^\\d]', '', km)\n",
    "            if km_val:\n",
    "                specs['Km Driven'] = km_val\n",
    "\n",
    "    # Try extracting year from car name\n",
    "    match = re.search(r'(19|20)\\d{2}', car_name)\n",
    "    if match:\n",
    "        specs['Manufacture Year'] = match.group()\n",
    "    \n",
    "    return specs\n",
    "\n",
    "def scrape_state(state):\n",
    "    \"\"\"Scrapes listings for a single state.\"\"\"\n",
    "    url = BASE_URL + quote_plus(state.lower())\n",
    "    time.sleep(uniform(1, 3))  # polite delay\n",
    "    response = requests.get(url, headers=HEADERS)\n",
    "    response.raise_for_status()\n",
    "    \n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    cards = soup.find_all('div', class_='NewUcExCard posR')\n",
    "\n",
    "    data = []\n",
    "    for card in cards:\n",
    "        name_tag = card.find('h3', class_='title')\n",
    "        car_name = name_tag.get_text(strip=True) if name_tag else \"N/A\"\n",
    "\n",
    "        location_tag = card.find('div', class_='distanceText')\n",
    "        location = location_tag.get_text(strip=True) if location_tag else state\n",
    "\n",
    "        price_tag = card.find('div', class_='Price hover')\n",
    "        price_text = price_tag.get_text(strip=True).lower() if price_tag else \"N/A\"\n",
    "        price = None\n",
    "        if 'lakh' in price_text:\n",
    "            price = float(re.sub(r'[^\\d.]', '', price_text)) * 1e5\n",
    "        elif 'crore' in price_text:\n",
    "            price = float(re.sub(r'[^\\d.]', '', price_text)) * 1e7\n",
    "\n",
    "        specs = extract_specs(card, car_name)\n",
    "        data.append({\n",
    "            'Car Name': car_name,\n",
    "            'Location': state,\n",
    "            'Price (INR)': round(price) if price else None,\n",
    "            'Fuel Type': specs['Fuel Type'],\n",
    "            'Transmission': specs['Transmission'],\n",
    "            'Km Driven': specs['Km Driven'],\n",
    "            'Manufacture Year': specs['Manufacture Year']\n",
    "        })\n",
    "    return data\n",
    "\n",
    "def scrape_all_states():\n",
    "    all_data = []\n",
    "    for state in STATES:\n",
    "        print(f\"Scraping {state}...\")\n",
    "        try:\n",
    "            all_data.extend(scrape_state(state))\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to scrape {state}: {e}\")\n",
    "    return pd.DataFrame(all_data)\n",
    "\n",
    "def clean_data(df):\n",
    "    \"\"\"Cleans and enriches the scraped data.\"\"\"\n",
    "    df['Km Driven'] = pd.to_numeric(df['Km Driven'], errors='coerce')\n",
    "    df['Manufacture Year'] = pd.to_numeric(df['Manufacture Year'], errors='coerce')\n",
    "    df['Price (INR)'] = df['Price (INR)'].fillna(0).astype(int)\n",
    "\n",
    "    # Extract car brand after year in name\n",
    "    df['Car Name'] = df['Car Name'].str.replace(r'(\\d{4})([A-Za-z])', r'\\1 \\2', regex=True)\n",
    "    df['Brand'] = df['Car Name'].str.extract(r'\\b(?:19|20)\\d{2}\\s+(\\w+)', expand=False)\n",
    "\n",
    "    return df.dropna(how='all').reset_index(drop=True)\n",
    "\n",
    "def main():\n",
    "    print(\"Starting scraper...\")\n",
    "    start = time.time()\n",
    "\n",
    "    df = scrape_all_states()\n",
    "    print(f\"\\nScraped {len(df)} rows.\")\n",
    "\n",
    "    df = clean_data(df)\n",
    "    print(f\"Cleaned data: {len(df)} rows.\")\n",
    "\n",
    "    filename = f\"used_cars_{pd.Timestamp.now():%Y%m%d_%H%M%S}.csv\"\n",
    "    df.to_csv(filename, index=False)\n",
    "    print(f\"\\nData saved to {filename} in {time.time() - start:.2f} seconds.\")\n",
    "    print(\"\\nSample:\")\n",
    "    print(df.head())\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22c40eb-0beb-4421-b64c-de9fc507d921",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
